{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiakolak/LyrAIcs/blob/main/lyrAIcs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJA5J39Dcl_R"
      },
      "source": [
        "# **LyrAIcs**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Some simple functions for visualizing audio signals + generating lyrics in different genres and moods using GPT-3. \n",
        "\n",
        "\n",
        "*How it Works:*\n",
        "---\n",
        "\n",
        "\n",
        "1. Upload an audio file \n",
        "2. Select a portion of the file (in seconds) you want to generate lyrics for \n",
        "3. Specify a mood, genre, sampling temperature, and an initial line to rhyme with, or go \"random mode\" and watch the chaos\n",
        "\n",
        "That's it! The model is configured to generate 10 sample lyrics at a time (can be changed in the API call, but don't reccomend increasing). What you do next is up to you. The lyrics are designed to fit the audio signal you selected, but if you don't want to use audio at all, you can just manually specify the parameter \"num_syllables\" (I would reccomend 9-14).  \n",
        "\n",
        "Or, if you want to go complete random mode, you can and let the model generate a lyric based only on your tone/genre/syllable spec. For this option, just check the \"random mode\" option (in the [Parameters](https://colab.research.google.com/drive/1e63PNY_CjogwGIEKr5OoXN244yPx-UZS#scrollTo=AeBl0EuRkmNf&line=14&uniqifier=1) cell).  \n",
        "\n",
        "\n",
        "*How I used it:*\n",
        "---\n",
        "\n",
        "For the song I showed in class, I took the output text for each 15 second clip and turned it into speech using [uberduck.ai](https://uberduck.ai/). This site recently went viral on TikTok and you can make some pretty hilarious stuff with it, but it's not ideal if you're trying to make something serious. \n",
        "\n",
        "After I had the speech, I just matched it up to the corresponding time frames in Logic. I would've liked to do this all in the notebook but I ran out of time so...sorry!  \n",
        "\n",
        "*Disclaimer:*\n",
        "---\n",
        "The model's output is unfiltered, so it may say something raunchy/offensive/poltiically incorrect, especially if you prompt it with certain types of phrases. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Q_hMA7ZcMA"
      },
      "source": [
        "Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLoeXxK5kCDa",
        "outputId": "b3d7a617-d197-453a-db41-a54da0512866"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install librosa\n",
        "!pip install IPython\n",
        "!pip install mir_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh8IEFduZnuj"
      },
      "source": [
        "Load imports/API key (you can use mine until it runs out ðŸ¤·)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ari8wZ3pkIXw"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import librosa\n",
        "from IPython.display import Audio\n",
        "import mir_eval.sonify\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy, scipy, matplotlib.pyplot as plt\n",
        "\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OosYEXQoYpxS",
        "outputId": "4611ad71-19be-402c-e89d-66cd4bab6a9e"
      },
      "outputs": [],
      "source": [
        "#@title Load the audio file \n",
        "#@markdown Ensure you have uploaded your backing track it to the root directory.\n",
        "#@markdown  Also, ignore the warning \"PySoundFile failed...\" if you are loading from a .mp3 file. \n",
        "\n",
        "path = 'audio.mp3'#@param {type:\"string\"}\n",
        "assert os.path.exists(path), \"The file does not exist.\"\n",
        "\n",
        "y, sr = librosa.load(path)\n",
        "y_harmonic, y_percussive = librosa.effects.hpss(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LfEOjhtZPcA",
        "outputId": "265d3ab0-d3e9-4a0f-ebb5-caf35b5a8ede"
      },
      "outputs": [],
      "source": [
        "#@title Select audio section:\n",
        "#@markdown Give the starting point and how long you want the clip to be (in seconds)  \n",
        "num_secs = 15#@param {type: \"number\"}\n",
        "start_sec = 10#@param {type:\"number\"}\n",
        "\n",
        "def get_segment(num_secs, start_sec, sr):\n",
        "  end_index = (start_sec + num_secs) * sr #sr is the sample rate\n",
        "  print(f'start:{start_sec}', f'end:{start_sec+num_secs} (sec)')\n",
        "  print(f'start:{start_sec*sr}', f'end:{end_index} (samples)')\n",
        "  audio_slice = y_percussive[start_sec*sr:end_index] #this gets you the sound data for those seconds \n",
        "  return audio_slice \n",
        "\n",
        "audio_slice = get_segment(num_secs, start_sec, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpyaC1tRaytQ"
      },
      "source": [
        "Play the audio snippet you selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "TcIi3YkWZbHq",
        "outputId": "15c803cc-9aae-4e78-cf60-aabe45d5eb95"
      },
      "outputs": [],
      "source": [
        "Audio(data=audio_slice, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBrIFqlOa9Qv"
      },
      "source": [
        "Plot the raw and binary audio signal "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "XlSPYRumcnsD",
        "outputId": "729ee5a8-5aa9-4cf6-c413-558a4e6374cb"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import step, show\n",
        "\n",
        "def convert_to_sec(audio_slice):\n",
        "  times = []\n",
        "  for i in range(len(audio_slice)):\n",
        "    time = i/22050\n",
        "    times.append(time)\n",
        "  return times\n",
        "\n",
        "def plot_raw(times, audio_slice):\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.plot(times,audio_slice)\n",
        "  plt.xlabel('Time (sec)')\n",
        "  plt.ylabel('Signal (Hz)')\n",
        "\n",
        "def make_binary(audio_slice):\n",
        "  mean = np.mean(audio_slice)\n",
        "  std_dev = np.std(audio_slice)\n",
        "  binary_audio = []\n",
        "  for i in range(len(audio_slice)):\n",
        "    s = audio_slice[i]\n",
        "    if s < mean-(2*std_dev):\n",
        "      binary_audio.append(1)\n",
        "    else:\n",
        "      binary_audio.append(0)\n",
        "  return binary_audio\n",
        "\n",
        "def plot_binary(times, audio_slice):\n",
        "  binary_audio = make_binary(audio_slice)\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.step(times, binary_audio)\n",
        "  plt.xlabel('Time (sec)')\n",
        "  plt.ylabel('Signal (Hz)')\n",
        "  return binary_audio\n",
        "\n",
        "times = convert_to_sec(audio_slice)\n",
        "plot_raw(times, audio_slice)\n",
        "binary_audio = plot_binary(times, audio_slice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "6omBbV3fgG0G",
        "outputId": "641d245d-2172-4c43-a9e5-b26828b8c394"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def count_events(times, binary_audio):\n",
        "  start,bin = 0, .2\n",
        "  cut = start+bin\n",
        "  bin_data = {}\n",
        "  for i in range(len(binary_audio)):\n",
        "    t = times[i]\n",
        "    s = binary_audio[i]\n",
        "    if t > cut:\n",
        "      cut = cut + .2\n",
        "    if cut not in bin_data:\n",
        "      bin_data[cut] = []\n",
        "    else:\n",
        "      bin_data[cut].append(s)\n",
        "  return bin_data\n",
        "\n",
        "def approx_syl(bin_dat):\n",
        "  same, diff = 0,0\n",
        "  compress = {}\n",
        "  for t, sigs in bin_dat.items():\n",
        "    if all(x==sigs[0] for x in sigs):\n",
        "      compress[t] = sigs[0]\n",
        "    else:\n",
        "      compress[t] = 1\n",
        "  return compress \n",
        "\n",
        "def count_beats(compress):\n",
        "  count = 0\n",
        "  for k,v in compress.items():\n",
        "    if v == 1:\n",
        "      count += 1\n",
        "  x = list(compress.keys())\n",
        "  y = list(compress.values())\n",
        "  return x,y,count\n",
        "\n",
        "def plot_beats(x,y):\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.plot(x,y)\n",
        "  plt.xlabel('Time (sec)')\n",
        "  plt.ylabel('Signal (Hz)')\n",
        "    \n",
        "bin_dat = count_events(times, binary_audio)\n",
        "compress = approx_syl(bin_dat)\n",
        "x,y,beats = count_beats(compress)\n",
        "plot_beats(x,y)\n",
        "\n",
        "print(\"approx # of total beat moments:\", beats)\n",
        "num_syllables=math.ceil(beats/7)\n",
        "print(\"aprox # of syllables per bar:\", num_syllables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yohLab4woM4"
      },
      "outputs": [],
      "source": [
        "def query_openai(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\", \n",
        "        temperature=temp,\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,\n",
        "        best_of=11,\n",
        "        n=10,\n",
        "        logprobs=1,\n",
        "    )\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZHtFknorxPO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeBl0EuRkmNf"
      },
      "outputs": [],
      "source": [
        "#@title Parameters\n",
        "#@markdown Genre and tone have a drop down bar of options to give you ideas, but you can add as many categories as you want by typing more words into the list \n",
        "\n",
        "#@markdown temperature range [0-1], 0=less random, 1=more random\n",
        "\n",
        "rhyme_phrase =  \"\"#@param {type:\"string\"}\n",
        "num_syllables = 8\n",
        "genre = \"country\" #@param [\"indie\", \"rock\", \"jazz\", \"country\", \"electronic\", \"hip-hop\", \"rap\", \"folk\", \"r&b\", \"pop\", \"reggae\"]\n",
        "tone = \"meloncholy\" #@param [\"excited\", \"funny\", \"wacky\", \"happy\", \"meloncholy\", \"hype\", \"eclectic\", \"chill\", \"soft\", \"sexy\"]\n",
        "temp =  1#@param {type:\"number\"}\n",
        "random_mode = True#@param {type:\"boolean\"}\n",
        "if not random_mode:\n",
        "  prompt = \"Write a lyric with {num_syllables} syllables, in the tone {tone} and genre {genre} that rhymes with: '{rhyme_phrase}'\".format(num_syllables=num_syllables, tone=tone, genre=genre, rhyme_phrase=rhyme_phrase)\n",
        "else:\n",
        "  prompt = \"Write a lyric with {num_syllables} syllables, in the tone {tone} and genre {genre} \".format(num_syllables=num_syllables, tone=tone, genre=genre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeUWwhCxpLnH",
        "outputId": "8a1a2feb-774d-44cc-e608-a56d4d3cd275"
      },
      "outputs": [],
      "source": [
        "response = query_openai(prompt)\n",
        "for result in response.choices:\n",
        "    print(prompt + \" \" + result.text)\n",
        "    print(\"\\n \\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
